# ğŸ‰ Complete Naukri Web Scraper - Feature Summary

## âœ… What's Been Built

A **production-ready, intelligent web scraper** for Naukri.com with advanced features:

### ğŸ” **Interactive Login System** (NEW!)
- Opens Naukri login page
- Waits 2 minutes for you to login manually
- Auto-detects successful login every 5 seconds
- Supports all login methods (email, Google, OTP)
- Proceeds automatically after login

### ğŸ” **Deep Scraping Mode**
- Clicks into each job posting
- Extracts actual apply links
- Identifies external vs Naukri applications
- Complete URL validation

### ğŸ“Š **Comprehensive Data Extraction**
For each job, extracts:
- âœ… Job title
- âœ… Company name
- âœ… Location
- âœ… Experience required
- âœ… Salary range
- âœ… Job description/skills
- âœ… Posted date
- âœ… Job details URL
- âœ… Apply link (actual application URL)
- âœ… Apply type (external/naukri)

### âš™ï¸ **Flexible Operation Modes**
1. **Quick Mode**: No login, basic info
2. **Standard Mode**: No login + deep scrape
3. **Full Mode**: Login + deep scrape (recommended)

### ğŸ“ **Output Format**
- Clean JSON structure
- Metadata included
- Timestamped files
- Fully structured data

---

## ğŸš€ Quick Start Commands

### 1. Test Run (No Login)
```bash
python naukri_scraper.py -k "Data Scientist" -l "Mumbai" -p 1
```

### 2. With Login (Recommended)
```bash
python naukri_scraper.py -k "Data Scientist" -l "Mumbai" -p 1 --login
```

### 3. Full Power Mode (Login + Deep Scrape)
```bash
python naukri_scraper.py -k "Python Developer" -l "Bangalore" -p 2 --login --deep-scrape
```

---

## ğŸ“– How It Works

### Without Login
```
1. Opens job search page
2. Scrolls to load all jobs
3. Extracts basic info from listing cards
4. Saves to JSON with "naukri" apply type
5. Links show "Login to Apply"
```

### With Login (Best!)
```
1. ğŸŒ Opens Naukri login page
2. â±ï¸ YOU LOGIN MANUALLY (2 min window)
3. âœ… Auto-detects successful login
4. ğŸ” Opens job search page
5. ğŸ“Š Scrolls to load all jobs
6. ğŸ¯ [If --deep-scrape] Clicks each job
7. ğŸ”— Extracts actual apply links
8. ğŸ’¾ Saves complete data to JSON
```

---

## ğŸ¯ Complete Usage Examples

### Daily Job Monitoring
```bash
# Morning routine - check new postings
python naukri_scraper.py \
  -k "Your Job Title" \
  -l "Your City" \
  -p 3 \
  --login \
  --deep-scrape \
  -o daily_jobs.json
```

### Multi-Role Search
```bash
# Search for multiple roles using batch scraper
# 1. Edit config.json with your searches
# 2. Run:
python batch_scraper.py
```

### Quick Check (No Login)
```bash
# Fast scan without login
python naukri_scraper.py -k "DevOps Engineer" -l "Pune" -p 1 --headless
```

---

## ğŸ“‹ All Command-Line Options

| Option | Short | Description | Example |
|--------|-------|-------------|---------|
| `--keyword` | `-k` | Job title/keyword (required) | `"Data Scientist"` |
| `--location` | `-l` | Job location | `"Mumbai"` |
| `--experience` | `-e` | Years of experience | `"2-5"` |
| `--pages` | `-p` | Number of pages | `2` |
| `--output` | `-o` | Output filename | `jobs.json` |
| `--login` | - | Login before scraping | (flag) |
| `--deep-scrape` | - | Visit each job for apply link | (flag) |
| `--headless` | - | Run without GUI | (flag) |

---

## ğŸ“ Project Files

```
naukri-web-scrapper/
â”‚
â”œâ”€â”€ naukri_scraper.py       # Main scraper with login
â”œâ”€â”€ batch_scraper.py        # Batch processing
â”œâ”€â”€ test_scraper.py         # Test script
â”œâ”€â”€ view_results.py         # View JSON results
â”‚
â”œâ”€â”€ config.json             # Batch config
â”œâ”€â”€ requirements.txt        # Dependencies
â”‚
â”œâ”€â”€ README.md              # Full documentation
â”œâ”€â”€ QUICK_START.md         # Getting started guide
â”œâ”€â”€ LOGIN_GUIDE.md         # Login feature guide
â”‚
â””â”€â”€ Output Files:
    â”œâ”€â”€ naukri_jobs_*.json        # Scraping results
    â”œâ”€â”€ scraping_results_*/       # Batch outputs
    â””â”€â”€ naukri_scraper.log        # Log file
```

---

## ğŸ“ Sample Workflow

### First Time Setup
```bash
# 1. Install dependencies (already done!)
pip install -r requirements.txt

# 2. Test basic scraping
python test_scraper.py

# 3. Try with login
python naukri_scraper.py -k "Your Job" -l "Your City" -p 1 --login
```

### Regular Use
```bash
# Login once, scrape multiple pages
python naukri_scraper.py \
  -k "Senior Python Developer" \
  -l "Bangalore" \
  -p 5 \
  --login \
  --deep-scrape \
  -o weekly_jobs.json

# View results
python view_results.py
```

---

## ğŸ’¡ Pro Tips

### 1. Combine Login + Deep Scrape
For best results, always use both:
```bash
--login --deep-scrape
```
This gives you actual, clickable apply links!

### 2. Login Once, Scrape Multiple Times
After login, the session persists. You can run multiple searches in the same session using batch_scraper.py.

### 3. Save Different Outputs
Use `-o` to save different searches:
```bash
python naukri_scraper.py -k "Python" -l "Mumbai" --login -o python_mumbai.json

python naukri_scraper.py -k "Java" -l "Mumbai" --login -o java_mumbai.json
```

### 4. Check Logs for Issues
If something goes wrong:
```bash
# View log file (note: it's in .gitignore by default)
# Run this to see it:
notepad naukri_scraper.log
```

---

## ğŸ¯ What You Can Do Now

âœ… **Scrape job listings** with complete information  
âœ… **Login interactively** to access apply links  
âœ… **Extract actual URLs** for direct applications  
âœ… **Batch process** multiple searches  
âœ… **Monitor jobs daily** with automated runs  
âœ… **Export to JSON** for further processing  

---

## ğŸš€ Next Steps

### Try It Now!
```bash
python naukri_scraper.py -k "Data Scientist" -l "Mumbai" -p 1 --login --deep-scrape
```

### What Happens:
1. Browser opens to Naukri login
2. You login (email, Google, whatever you prefer)
3. Scraper detects login
4. Starts scraping automatically
5. Visits each job to get apply links
6. Saves everything to JSON

**That's it! You're ready to supercharge your job hunting! ğŸ‰**

---

## ğŸ“ Files to Check

- **Full Docs**: `README.md`
- **Quick Start**: `QUICK_START.md`
- **Login Guide**: `LOGIN_GUIDE.md`
- **Test Script**: `test_scraper.py`
- **View Results**: `view_results.py`

Happy job hunting! ğŸ¯ğŸš€
